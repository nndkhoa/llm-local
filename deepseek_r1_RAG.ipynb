{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nndkhoa/llm-local/blob/main/deepseek_r1_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!pip install -U langchain-ollama\n",
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ],
      "metadata": {
        "id": "sbq7rZiTTP5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRyjEafYQu_T"
      },
      "outputs": [],
      "source": [
        "%xterm\n",
        "# OLLAMA_HOST=\"0.0.0.0\" OLLAMA_ORIGINS=\"*\" ollama serve\n",
        "# Chạy xong lệnh trên thì để yên nó ở đây"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm\n",
        "# ollama pull deepseek-r1 & ollama pull nomic-embed-text\n",
        "# Xong có thể clear output cho gọn"
      ],
      "metadata": {
        "id": "jTN6cM8KJYsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_ollama.llms import OllamaLLM\n",
        "llm = OllamaLLM(model=\"deepseek-r1\")"
      ],
      "metadata": {
        "id": "wx3iazknRweg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chỉ tạo để test ollama đang chạy\n",
        "response = llm.invoke(\"who are your?\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "PbwX5idyGaYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50726d57-8f05-4135-cd83-42a20ce6e103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "\n",
            "</think>\n",
            "\n",
            "Greetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mở thêm một tab nữa để cung cấp api\n",
        "%xterm\n",
        "\n",
        "# ssh -p 443 -R0:localhost:11434 qr@a.pinggy.io\n",
        "\n",
        "# Test cục bộ với\n",
        "# curl http://localhost:11434/api/generate -d '{ \"model\": \"deepseek-r1\", \"prompt\": \"Who are you?\", \"stream\": false}'\n",
        "\n"
      ],
      "metadata": {
        "id": "ykrii-c8LyEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test với local địa chỉ sinh ra, ví dụ: http://rncli-35-203-177-46.a.free.pinggy.link\n",
        "\n",
        "# curl  http://rnikh-35-197-47-109.a.free.pinggy.link/api/generate -d '{ \"model\": \"deepseek-r1\", \"prompt\": \"Who are you?\", \"stream\": false}'"
      ],
      "metadata": {
        "id": "eH6hKCPBOMPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm\n",
        "\n",
        "# curl http://localhost:11434/api/generate -d '{ \"model\": \"deepseek-r1\", \"prompt\": \"Who are you?\", \"stream\": false}'"
      ],
      "metadata": {
        "id": "vfAlJxEPQPVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio ollama chromadb langchain-community langchain-core"
      ],
      "metadata": {
        "id": "rXPYn-zJVfOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "\n",
        "# Load the data from the web URL\n",
        "url = 'https://vnexpress.net/de-xuat-thoi-gian-lam-viec-du-ngan-de-nam-nu-co-thoi-gian-tim-ban-doi-4778404.html'\n",
        "loader = WebBaseLoader(url)\n",
        "docs = loader.load()\n",
        "\n",
        "# or load the text from pdf\n",
        "# path = \"../data/Understanding_Climate_Change.pdf\"\n",
        "# loader = PyPDFLoader(path)\n",
        "# documents = loader.load()\n",
        "\n",
        "# Split the loaded documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Create Ollama embeddings and vector store\n",
        "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\") # or use (model = \"llama3\")\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
        "\n",
        "# Define the function to call the Ollama Llama3 model\n",
        "def ollama_llm(question, context):\n",
        "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
        "    response = ollama.chat(model='deepseek-r1', messages=[{'role': 'user', 'content': formatted_prompt}])\n",
        "    return response['message']['content']\n",
        "\n",
        "# Define the RAG setup\n",
        "retriever = vectorstore.as_retriever() # as_retriever(search_kwargs={\"k\": 2})\n",
        "\n",
        "def rag_chain(question):\n",
        "    retrieved_docs = retriever.invoke(question)\n",
        "    formatted_context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "    return ollama_llm(question, formatted_context)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sqHcRXDPVSfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Giao diện nhập liệu form bên trong Colab\n",
        "import gradio as gr\n",
        "iface = gr.Interface(\n",
        "  fn=rag_chain,\n",
        "  inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
        "  outputs=\"text\",\n",
        "  title=\"RAG with Llama3.1\",\n",
        "  description=\"Ask questions about the provided context\",\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "Gz82MCMdfHUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rag_chain(\"Tóm tắt nội dung bài viết\"))"
      ],
      "metadata": {
        "id": "eBzhw20qfJ37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aebab693-17ae-4501-c167-980df831be63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "Okay, I need to summarize the content of this Vietnamese article. The article starts by talking about Vietnamese laws limiting couples to having 1-2 children, which has been in place for several years. Each age group has different policies, and currently, penalties for having a third child are applied. However, these penalties don't seem appropriate anymore because Vietnam is facing a population decline that's below replacement level but could become a major issue without intervention.\n",
            "\n",
            "The article mentions that the Vietnamese government will continue to review its population policies to make them better suited to current realities in the near future, aiming for the best demographic structure and quality in the long run. There's also a forecast of the law from the Prime Minister scheduled for December 2025.\n",
            "\n",
            "Looking at the additional content section, there's an article about suggesting the optimal time frame for working so that men and women can have enough time to find their life partners. It talks about balancing work and personal life to help people meet their partners, referencing experts on family planning and labor laws.\n",
            "\n",
            "I should focus on summarizing the key points: current policy limitations, the decline in population, the need for new policies, government's commitment to review, and the suggestion regarding working hours for better personal relationships.\n",
            "</think>\n",
            "\n",
            "Tóm tắt nội dung bài viết:\n",
            "\n",
            "- **Pháp định số lượng con**: Trong những năm gần đây, quy định cho mỗi giai đoạn hônFolders chỉ có thể sinh được 1 đến 2 con. Tuy nhiên, hiện tại các Nghị định xử phạt cho người sinh con thứ ba không còn phù hợp với thực tế hiện tại, đặc biệt là vớiissu về độ giảm population trong Việt Nam.\n",
            "\n",
            "- **Nghĩa isu populaotr và giải pháp**: Việt Nam đang gặp khó khăn với sự giảm số dân, chưa ở mức bao động nhưng có thể trở thành một vấn đề quan trọng nếu không có các giải pháp can thiệp hiện tại. Do đó, việc nới lỏng quy định sinh 1-2 con đã được áp dụng trong những năm trước đây là cần thiết để giúp gia đình và xã hộipopulation healthy growth.\n",
            "\n",
            "- **Pháp lý số population**: Cụ thể, \"Cục Dân số\" sẽ tiếp tục tham khảo và hoàn thiện các Nghị định về dân số với focus phù hợp cho thực tế hiện tại để chắc chắn có population qual và quantity tốt nhất trong tương lai.\n",
            "\n",
            "- **Thư viện kiến nghị**: Liên quan đến việc tìm bạn đời, bài viết cũng đề xuất một số dựi time frame làm việc để người phụ nữ có thể tìm được người vợ từ waktu làm việc đủ trong vòng 5 đến 10 năm, giúp giảm áp lực trong việc tìm h subscription.\n",
            "\n",
            "- **Kết luận**: Tóm lại, các fused concepts về population and labor market cần được tập trung và giải quyết together to ensure population stability và phát triển.\n"
          ]
        }
      ]
    }
  ]
}